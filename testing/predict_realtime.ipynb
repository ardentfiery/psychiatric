{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7555,"status":"ok","timestamp":1709448428257,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"},"user_tz":-345},"id":"ngWrY6DRvb-v","outputId":"76e8945f-a7a1-44b3-b340-7d3ccbef2c99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.25.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n"]}],"source":["!pip install keras_preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7756,"status":"ok","timestamp":1709448436009,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"},"user_tz":-345},"id":"spNTW98Hvhc3","outputId":"86d4899a-f757-4ed0-b4a1-e79be67d96d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.8)\n"]}],"source":["!pip install dill"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJ-GO68T_hGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709448436009,"user_tz":-345,"elapsed":7,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"}},"outputId":"a2b8e1c3-bf11-45f9-96e3-1872579c214b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}],"source":["import functools\n","import operator\n","import os\n","import cv2\n","import time\n","import numpy as np\n","import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer"]},{"cell_type":"code","source":["def vader_sentiment_analysis(text):\n","  analyzer = SentimentIntensityAnalyzer()\n","  sentiment_scores = analyzer.polarity_scores(text)\n","  compound_score = sentiment_scores['compound']\n","\n","  if compound_score >= 0.05:\n","    return \"POSITIVE\"\n","  elif compound_score <= -0.05:\n","    return \"NEGATIVE\"\n","  else:\n","    return \"NEUTRAL\""],"metadata":{"id":"gUzMJCW-Khiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11251,"status":"ok","timestamp":1709448447256,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"},"user_tz":-345},"id":"vqmNXUqJAT9T","outputId":"68726845-4ba5-4448-9a2c-bb6f8a324ec8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n","=================================================================\n","Total params: 134260544 (512.16 MB)\n","Trainable params: 134260544 (512.16 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Model loaded\n"]}],"source":["%run \"/content/drive/MyDrive/Colab Notebooks/preprocessing2.ipynb\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYSC--P5ApWh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709448448124,"user_tz":-345,"elapsed":873,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"}},"outputId":"af0685be-6135-4c7a-f922-d165d50356e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.005\n","400\n"]}],"source":["%run \"/content/drive/MyDrive/Colab Notebooks/config.ipynb\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHUzrCoOAqxS","executionInfo":{"status":"ok","timestamp":1709448448740,"user_tz":-345,"elapsed":620,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"774a13d6-e737-4023-dfe3-faa7a3f7d4b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.005\n","400\n","50\n","400\n","/content/drive/MyDrive/N_model_lr5e-3\n","30\n"]}],"source":["%run \"/content/drive/MyDrive/Colab Notebooks/inference_model.ipynb\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcPw22AhK5AP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709448450109,"user_tz":-345,"elapsed":1373,"user":{"displayName":"Pradip Dong","userId":"04830575459773971005"}},"outputId":"fecc3c9b-5ac0-4f86-e059-b149e300d812"},"outputs":[{"output_type":"stream","name":"stdout","text":["Video FPS: 0\n","Total Frames: 0\n","frame extraction time: 0.06521248817443848 seconds\n","50 frames randomly selected and saved successfully!\n","\n","\n"]}],"source":["%run \"/content/drive/MyDrive/Colab Notebooks/vid_to_frames.ipynb\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvSUim88AwoV"},"outputs":[],"source":["class VideoDescriptionRealTime(object):\n","  \"\"\"\n","  Initialize the parameters for the model\n","  \"\"\"\n","  def __init__(self):\n","    self.latent_dim = latent_dim\n","    self.num_encoder_tokens = num_encoder_tokens\n","    self.num_decoder_tokens = num_decoder_tokens\n","    self.time_steps_encoder = time_steps_encoder\n","    self.max_probability = max_probability\n","\n","    self.tokenizer, self.inf_encoder_model, self.inf_decoder_model = inference_model()\n","    self.save_model_path = save_model_path\n","    self.test_path = test_path\n","    self.search_type = search_type\n","    self.num = 0\n","\n","  def greedy_search(self, loaded_array):\n","    \"\"\"\n","    :param f: the loaded numpy array after creating videos to frames and extracting features\n","    :return : the final sentence which has been predicted greedily\n","    \"\"\"\n","    inv_map = self.index_to_word()\n","    states_value = self.inf_encoder_model.predict(loaded_array.reshape(-1, 50, 4096))\n","    target_seq = np.zeros((1, 1, 400))\n","    final_sentence = ''\n","    target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n","    for i in range(15):\n","      output_tokens, h, c = self.inf_decoder_model.predict([target_seq] + states_value)\n","      states_value = [h, c]\n","      output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n","      y_hat = np.argmax(output_tokens)\n","      if y_hat == 0:\n","        continue\n","      if inv_map[y_hat] is None:\n","        break\n","      if inv_map[y_hat] == 'eos':\n","        break\n","      else:\n","        final_sentence = final_sentence + inv_map[y_hat] + ' '\n","        target_seq = np.zeros((1, 1, 400))\n","        target_seq[0, 0, y_hat] = 1\n","\n","    final_sentence = final_sentence.strip().capitalize()\n","\n","    final_sentence = final_sentence.rstrip() + '.'\n","\n","    return final_sentence\n","\n","  def index_to_word(self):\n","    index_to_word = {value: key for key, value in self.tokenizer.word_index.items()}\n","    return index_to_word\n","\n","  def get_video(self):\n","    video_folder = '/content/drive/MyDrive/realtimeVideo'\n","\n","    video_list = os.listdir(video_folder)\n","\n","    video_files = [video for video in video_list if video.endswith('.mov')]\n","\n","    video_name = video_files[self.num] # name with extension\n","    video_id = os.path.splitext(video_name)[0] # name without extension\n","\n","    save_path = \"/content/drive/MyDrive/VideoFrame\"\n","\n","    model = load_vgg16()\n","\n","    video_path = os.path.join(video_folder, video_name)\n","    video_to_frames(video_path, save_path)\n","    frames_save_path = os.path.join(save_path, video_id)\n","\n","    start_time = time.time()\n","\n","    features = feature_extraction(frames_save_path, model)\n","\n","    end_time = time.time()\n","    difference = end_time - start_time\n","    print(f\"feature extraction time: {difference} seconds\")\n","    print(features.shape)\n","    print('\\n')\n","\n","    if self.num < len(video_files):\n","      self.num += 1\n","    else:\n","      self.num = 0\n","\n","    return features, video_name\n","\n","  def test(self):\n","    X_test, filename = self.get_video()\n","\n","    if self.search_type == 'greedy':\n","      start_time = time.time()\n","      sentence_predicted = self.greedy_search(X_test.reshape((-1, 50, 4096)))\n","      end_time = time.time()\n","      difference = end_time - start_time\n","      print(f\"caption prediction time: {difference} seconds\")\n","      print('\\n')\n","\n","    self.max_probability = -1\n","\n","    return sentence_predicted, filename"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kk2ck4Wddd5c","outputId":"9ee80af4-9681-4167-f132-3fb334c52a3e"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stdout","output_type":"stream","text":["Video FPS: 30\n","Total Frames: 252\n","frame extraction time: 4.755063772201538 seconds\n","50 frames randomly selected and saved successfully!\n","\n","\n","1/1 [==============================] - 32s 32s/step\n","\n","\n","feature extraction time: 41.68971657752991 seconds\n","(50, 4096)\n","\n","\n","1/1 [==============================] - 1s 578ms/step\n","1/1 [==============================] - 0s 465ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","caption prediction time: 1.6939358711242676 seconds\n","\n","\n","Generated caption: A patient is taking rest.\n","\n","\n","It takes 57.95 seconds to generate caption.\n","\n","\n","NEUTRAL\n","\n","\n","Video FPS: 30\n","Total Frames: 249\n","frame extraction time: 5.830034017562866 seconds\n","50 frames randomly selected and saved successfully!\n","\n","\n","1/1 [==============================] - 32s 32s/step\n","\n","\n","feature extraction time: 32.655274868011475 seconds\n","(50, 4096)\n","\n","\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 26ms/step\n","caption prediction time: 0.8878083229064941 seconds\n","\n","\n","Generated caption: A patient is drinking water.\n","\n","\n","It takes 43.83 seconds to generate caption.\n","\n","\n","NEUTRAL\n","\n","\n","Video FPS: 30\n","Total Frames: 129\n","frame extraction time: 17.278526782989502 seconds\n","50 frames randomly selected and saved successfully!\n","\n","\n","1/1 [==============================] - 34s 34s/step\n","\n","\n","feature extraction time: 34.15129804611206 seconds\n","(50, 4096)\n","\n","\n","1/1 [==============================] - 0s 311ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","caption prediction time: 1.0743517875671387 seconds\n","\n","\n","Generated caption: A patient is acting weird.\n","\n","\n","It takes 57.00 seconds to generate caption.\n","\n","\n","NEGATIVE\n","\n","\n","Video FPS: 30\n","Total Frames: 1179\n","frame extraction time: 2.952094793319702 seconds\n","50 frames randomly selected and saved successfully!\n","\n","\n","1/1 [==============================] - 32s 32s/step\n","\n","\n","feature extraction time: 41.562779664993286 seconds\n","(50, 4096)\n","\n","\n","1/1 [==============================] - 0s 218ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","caption prediction time: 1.1317825317382812 seconds\n","\n","\n","Generated caption: A patient is using stuff around.\n","\n","\n","It takes 50.83 seconds to generate caption.\n","\n","\n","NEUTRAL\n","\n","\n","Want to predict caption for next video? n\n"]}],"source":["if __name__ == \"__main__\":\n","  video_to_text = VideoDescriptionRealTime()\n","\n","  while True:\n","    start = time.time()\n","    video_caption, file = video_to_text.test()\n","    end = time.time()\n","    print('Generated caption:', video_caption)\n","\n","    print('\\n')\n","    print('It takes {:.2f} seconds to generate caption.'.format(end-start))\n","    print('\\n')\n","\n","    # Perform sentiment analysis\n","    result = vader_sentiment_analysis(video_caption)\n","\n","    # Display sentiment analysis results\n","    print(result)\n","    print('\\n')"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"15fJt0EDsTUrSsgz1Or7EvH-J9-EjHfEF","authorship_tag":"ABX9TyMB0Un2KmtLh0wEXX0vPc3K"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}